{"cells":[{"cell_type":"markdown","metadata":{"id":"ZDitZsQALa1H"},"source":["# HANDS-ON PRACTICE: NEURAL NETWORKS FUNDAMENTALS"]},{"cell_type":"markdown","metadata":{"id":"Wi84rOu4si0V"},"source":["SO Basics of Neural Networks 2023 school at the IAA-CSIC. Nov 2023.  \n","Eduardo Sánchez Karhunen  (fesanchez@us.es)  \n","University of Seville. Spain.  Dept. of CS and Artificial Inteligence\n"]},{"cell_type":"markdown","metadata":{"id":"pi-LyvK2V070"},"source":["### Introduction"]},{"cell_type":"markdown","metadata":{"id":"1EQPOjdLUGZC"},"source":["In this hands-on practice we are going to tackle an image classification problem, in concrete the Galaxy10 dataset. For educational purposes, we will design a MLP (Multilayer Perceptron) form scratch.\n","\n","As you probably know, the Galaxy10 SDSS contains 21.785 galaxy colored images (69x69 pixels) separated in 10 classes. Galaxy10 SDSS images come from Sloan Digital Sky Survey and labels come from Galaxy Zoo.\n","\n","Galaxy10 dataset (21785 images)  \n","├── Class 0 (3461 images): Disk, Face-on, No Spiral  \n","├── Class 1 (6997 images): Smooth, Completely round  \n","├── Class 2 (6292 images): Smooth, in-between round  \n","├── Class 3 (394 images): Smooth, Cigar shaped  \n","├── Class 4 (1534 images): Disk, Edge-on, Rounded Bulge  \n","├── Class 5 (17 images): Disk, Edge-on, Boxy Bulge  \n","├── Class 6 (589 images): Disk, Edge-on, No Bulge  \n","├── Class 7 (1121 images): Disk, Face-on, Tight Spiral  \n","├── Class 8 (906 images): Disk, Face-on, Medium Spiral  \n","└── Class 9 (519 images): Disk, Face-on, Loose Spiral  \n","\n","These classes are mutually exclusive, Galaxy10 is meant to be an alternative to MNIST or Cifar10 as a deep learning toy dataset for astronomers. Thus astroNN.models.Cifar10_CNN is used with Cifar10 as a reference.\n","\n","The original images are 424x424, but were cropped to 207x207 centered at the images and then downscaled 3 times via bilinear interpolation to 69x69 in order to make them manageable on most computer and graphics card memory.\n","\n","There is no guarantee on the accuracy of the labels. Moreover, Galaxy10 is not a balanced dataset and it should only be used for educational or experimental purpose.\n"]},{"cell_type":"markdown","metadata":{"id":"tLgenWShFb0N"},"source":["### 1. Loading libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3FXwlSEgKYa"},"outputs":[],"source":["import numpy as np\n","import h5py\n","import tensorflow as tf\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"kVhPclDLgYUu"},"source":["### Exercise 0: Dataset preparation"]},{"cell_type":"markdown","metadata":{"id":"iCjX9i4egb-q"},"source":["First of all, we will download the dataset to our local disk. In this case our dataset can be downloaded from a site in the network. Typically this operation is easily performed using the `wget` command with this syntax:\n","\n","```wget http_site_direction```\n","\n","Note: OS commands can be called from jupyter notebooks inserting a `!` before the command. E. g. if we want to inspect the files in our directory:\n","\n","```!ls -ls```\n","\n","Our dataset can be downloaded from ```http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5```."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4802,"status":"ok","timestamp":1699113288867,"user":{"displayName":"Eduardo Sanchez Karhunen","userId":"07705693878574082533"},"user_tz":-60},"id":"A6x2TeCbjZ95","outputId":"d1f0c96d-a216-498c-827f-27d3202a8bd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-04 15:54:44--  http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\n","Resolving www.astro.utoronto.ca (www.astro.utoronto.ca)... 128.100.89.92\n","Connecting to www.astro.utoronto.ca (www.astro.utoronto.ca)|128.100.89.92|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 210234548 (200M)\n","Saving to: ‘Galaxy10.h5’\n","\n","Galaxy10.h5         100%[===================>] 200.50M  49.5MB/s    in 4.5s    \n","\n","2023-11-04 15:54:48 (45.1 MB/s) - ‘Galaxy10.h5’ saved [210234548/210234548]\n","\n"]}],"source":["# your code here\n","\n","!wget http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5"]},{"cell_type":"markdown","metadata":{"id":"r9HHkcMxjfAN"},"source":["Now we have a h5 file in our local disk. It must be converted into numpy arrays to feed them to any machine learning model, including neural netowrks.\n","\n","These numpy arrays are obtained reading this h5 file using the command:\n","\n","```hf = h5py.File(file_name, 'r')```\n","\n","This data structure is similar to a Python dictionary with two keys:\n","* ans: containing the labels.\n","* images: with the images.\n","\n","Using the `get` command, this dictionary can be converted into numpy dataarrays.\n","A common use is:\n","\n","```a = hf.get(key)[()]```\n","\n","Create two numpy arrays containing images and labels from the previously downloaded h5 file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjrXTGkNgWCt"},"outputs":[],"source":["# your code here\n","\n","hf = h5py.File('Galaxy10.h5', 'r')\n","labels, images = hf.get('ans')[()], hf.get('images')[()]"]},{"cell_type":"markdown","metadata":{"id":"P8fXWNW0m09i"},"source":["Check the shape of the dataset: number of images and its shape."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1699113317933,"user":{"displayName":"Eduardo Sanchez Karhunen","userId":"07705693878574082533"},"user_tz":-60},"id":"WDKwAL3KmboB","outputId":"6c900425-0419-4857-ca9e-aec3a8b82252"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of images: 21785\n","shape of each image: [69, 69]\n","number of channels: 3\n"]}],"source":["# your code here\n","\n","n_images, *shape, n_channels = images.shape\n","print(f\"number of images: {n_images}\")\n","print(f\"shape of each image: {shape}\")\n","print(f\"number of channels: {n_channels}\")"]},{"cell_type":"markdown","metadata":{"id":"9X3nN-ChoqoE"},"source":["MLP networks can not handle multichannel images. Hence, we will convert them into grayscale images. For that purpose, calculate the mean of the three layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3955,"status":"ok","timestamp":1699113452785,"user":{"displayName":"Eduardo Sanchez Karhunen","userId":"07705693878574082533"},"user_tz":-60},"id":"fcRdb2sPoeyF","outputId":"183de7bf-ed5b-4e49-8841-a3035ee9da78"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(21785, 69, 69)"]},"metadata":{},"execution_count":8}],"source":["# your code here\n","\n","images_new = np.array([np.mean(image, axis=2) for image in images])\n","images_new.shape"]},{"cell_type":"markdown","metadata":{"id":"pXIX7lGyu2Nc"},"source":["### Exercise 1. Create train and test datasets"]},{"cell_type":"markdown","metadata":{"id":"97_KZhmhvaiU"},"source":["Divide the dataset into two new datasets for:\n","* training: 90%\n","* test: 10%  \n","\n","Use the `train_test_split` command from scikit_learn. Do not worry for the validation dataset. We will create it on-the-fly during the model training process.\n","\n","More info in: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","\n","**Task:** Create the following arrays: `train_images`, `train_labels`, `test_images` and `test_labels`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ecy460wawD1J"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7tyB8qj8zFjl"},"source":["### Exercise 2. Normalize image pixel values"]},{"cell_type":"markdown","metadata":{"id":"Ev8LfFKN-VRP"},"source":["Remember that one of the great advantages of Deep Learning is a simplified preprocessing pipeline. In our case, only a normalization is needed, e.g. dividing all pixel values by their maximum value: 255.\n","\n","**Task:** Divide train and test images by 255.0."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQG4v6qFxxUK"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GpvRWsl7_BTX"},"source":["### Build the MLP model"]},{"cell_type":"markdown","metadata":{"id":"mSsim3bj_QLA"},"source":["Our next steps are related to the design of the MLP to solve the problem. Lets consider a simple 2 hidden layer architecture:\n","\n","![picture](https://drive.google.com/uc?id=1RXlmNK1E_E2fbqNfiqKGvtfkWTKfElb1)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PCFr6e_jDb8D"},"source":["### Exercise 3. Create the input layer."]},{"cell_type":"markdown","metadata":{"id":"x3xbAOQlDgQn"},"source":["Remember:\n","* MLP can only process 1D arrays. Hence, images must be flattened.\n","* The number of neurons of the input layer is the number of features of each data sample. In image problems, each pixel of the image is a feature.  \n","\n","More info in https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten\n","\n","**Task:** Create the input layer for our model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h31DNWoBCFCT"},"outputs":[],"source":["# type your code here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KildGm4hGFSm"},"source":["### Exercise 4. Create hidden layers."]},{"cell_type":"markdown","metadata":{"id":"H43Odrt0GFgF"},"source":["Create two hidden layers:\n","* Follow the idea of a reduction of the dimensionality step by step.\n","* Remember that the hidden layers use relu as activation function.\n","\n","More info in: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n","\n","**Task:**  Create two layers with 500 and 100 neurons, respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zRjHMitHDWv"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"c8kIS3u2IE6U"},"source":["### Exercise 5. Create the output layer."]},{"cell_type":"markdown","metadata":{"id":"71j6pNqpIFIm"},"source":["Do not forget:\n","* The number of neurons of this layer is the number of classes.\n","* Its activation function is sigmoid (if 2 classes) or softmax (if >2 classes)\n","\n","**Task:** Create the proper output layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Se_GsUM9IvLB"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4nNvqt3JJDrM"},"source":["### Exercise 6. Join all layers in a MLP"]},{"cell_type":"markdown","metadata":{"id":"o0Ckn1JFJDzi"},"source":["Remember: the first step is to create a `sequential` structure to be filled with the previously created layers.\n","\n","More info in: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n","\n","**Task:** Collect all the previous layers in a model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOi42HQEJ2Yt"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","source":["### Exercise 7. Inspect model"],"metadata":{"id":"pU4zT3O0sfGu"}},{"cell_type":"markdown","source":["Show a summary of the model, with info of each layer:\n","* name and type of layer\n","* output shape\n","* number of parameters\n","\n","This info is useful to check if the model has been built properly and, very important, to be conscious of the huge number of parameters to train.\n","\n","**Task:** show a summary of the network\n"],"metadata":{"id":"9n6i3ftJvqWS"}},{"cell_type":"code","source":["# your code here\n","\n"],"metadata":{"id":"dt_lQeyssnFo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ob6iG2AKnAg"},"source":["### Exercise 8. Assign loss function and optimizer"]},{"cell_type":"markdown","metadata":{"id":"rcO61kgUKnMw"},"source":["Before training a model some details must be set:\n","* A loss function to be optimized. In classification problems, cross_entropy is considered:\n","    - 2 classes: binary cross entropy\n","    - +2 classes: categorical cross entropy\n","\n","If the class label is not codified using one_hot, we use sparse_categorical_crossentropy.\n","\n","More info in: https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n","\n","* An optimization \"technique\" to reduce the loss funtion up to a local minimum Typically, an adam optimizer is considered for training DL models.\n","\n","More info in: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n","\n","Task: Indicate to the netowrk the selected loss function and optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foO3WkdvLBpP"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GZ-rDDyxN3q6"},"source":["### Exercise 9. Train the network"]},{"cell_type":"markdown","metadata":{"id":"-mPWZtqjN33d"},"source":["At this point, two final decision must be taken:\n","* How many epochs our model will be trained on. In this concrete problem, beyond 7 or 10 epochs there is no improvement.\n","* A validation dataset must be provided to the model. Typically 20% of the training dataset is more than enough for our purposes. Use the parameter `validation_split` to indicate this value to the model training.\n","\n","You should obtain an accuracy on the validation dataset around 68-69%\n","\n","**Task:** Train the model with the selected number of epochs and validation_split parameter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKsg-lj4OESP"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","source":["### Exercise 10: Plot training history"],"metadata":{"id":"XJdEtcPHtQOM"}},{"cell_type":"markdown","source":["It is a good practice to plot our training curves. Typically we compare the evolution of loss function (accuracy) vs epochs."],"metadata":{"id":"5sbhX2S_w--J"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwbWpeimYxD8"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","source":["### Exercise 11. Evaluate model accuracy"],"metadata":{"id":"hu8QYYqrtzum"}},{"cell_type":"markdown","metadata":{"id":"KbiNtUFmdPwD"},"source":["**Task:** Once trained the model, obtain the accuracy of the model on the test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gj0sNN4NdQA-"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","source":["### Exercise 12: Making predictions with the model"],"metadata":{"id":"WBZVdHVBvTdJ"}},{"cell_type":"markdown","source":["Given an input image, the `predict` method returns the output of the last layer. This output is interpreted as the probability of the image to correspond to each of the classes.\n","\n","**Task:** Inject to the model 3 images from the test dataset to obtain their probabilities."],"metadata":{"id":"jdpuyqs0wLG6"}},{"cell_type":"code","source":["# your code here\n","\n"],"metadata":{"id":"98n5WehPvT0n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYcLKXWdjjK0"},"source":["**Task:** Using `np.argmax` and the probabilities, decide which is the class of each image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5aTnq2ggf8Y"},"outputs":[],"source":["# your code here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MwYtZX7WlRJr"},"source":["Task: Finally, compare the predicted classes with the real ones. There should be approx. 2/3 of correct predictions (or if we are lucky, even more)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJIsn41Hgu_b"},"outputs":[],"source":["# your code here\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}